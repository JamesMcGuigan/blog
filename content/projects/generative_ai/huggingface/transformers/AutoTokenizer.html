<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="GPT4">

<title>AutoTokenizer</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../../">
<script src="../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-27712984-4', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script>
var MemberSpace = window.MemberSpace || {"subdomain": "jamesmcguigan"};
(function (d) {
    var s = d.createElement("script");
    s.src = "https://cdn.memberspace.com/scripts/widgets.js";
    var e = d.getElementsByTagName("script")[0];
    e.parentNode.insertBefore(s, e);
}(document));
</script>


<link rel="stylesheet" href="../../../../../assets/styles.css">
<meta property="og:title" content="AutoTokenizer">
<meta property="og:description" content="">
<meta name="twitter:title" content="AutoTokenizer">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="@JamesMcGuigan42">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../index.html" rel="" target="">
 <span class="menu-text">James McGuigan</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../content/websites/index.html" rel="" target="">
 <span class="menu-text">Websites</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../content/essays/index.html" rel="" target="">
 <span class="menu-text">Essays</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../../../../content/projects/index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Projects</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/JamesMcGuigan42" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/jamesmcguigan/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/JamesMcGuigan" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.kaggle.com/jamesmcguigan" rel="" target=""><i class="bi bi-kaggle" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://stackoverflow.com/users/748503/james-mcguigan" rel="" target=""><i class="bi bi-stackoverflow" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Generative Ai</li><li class="breadcrumb-item"><a href="../../../../../content/projects/generative_ai/huggingface/transformers/index.html">HuggingFace</a></li><li class="breadcrumb-item"><a href="../../../../../content/projects/generative_ai/huggingface/transformers/index.html">Transformers</a></li><li class="breadcrumb-item"><a href="../../../../../content/projects/generative_ai/huggingface/transformers/AutoTokenizer.html">AutoTokenizer</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Projects</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Generative Ai</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">HuggingFace</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../content/projects/generative_ai/huggingface/transformers/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth3 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/generative_ai/huggingface/transformers/AutoConfig.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AutoConfig</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/generative_ai/huggingface/transformers/AutoModel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AutoModel</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/generative_ai/huggingface/transformers/AutoTokenizer.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">AutoTokenizer</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../content/projects/Subatomic_Playground/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Subatomic Playground</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">ChatGPT</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/1_Subatomic_Shenanigans.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Subatomic Shenanigans</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/2_Subatomic_Playground.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Subatomic Playground</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/3_React_Technology_Stack.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">React Technology Stack</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/4_iOS_Technology_Stack.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">iOS Technology Stack</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/5_React_Native_Tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">React Native Tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Level Design</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth3 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Black_Hole_Escape.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Black Hole Escape</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Cosmic_Balance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Cosmic Balance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Particle_Collider_Challenge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Particle Collider Challenge</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Quantum_Entanglement_Puzzle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantum Entanglement Puzzle</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Quantum_Realm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantum Realm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Quantum_Tunnel_Puzzle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantum Tunnel Puzzle</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Relativity_Ride.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Relativity Ride</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Spacetime_Construction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spacetime Construction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Star_Formation_Simulator.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Star Formation Simulator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/ChatGPT/Level_Design/Time_Dilation_Race.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Time Dilation Race</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Claude</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/1_Feedback_for_ChatGPT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Feedback for ChatGPT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/2_Specifications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Specifications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/3_Integrated_Mechanics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Integrated Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/4_Educational_Integration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Educational Integration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/5_Adaptive_Difficulty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Adaptive Difficulty</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/6_Comprehensive_Overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comprehensive Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/7_Tutorial_Unity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/8_Web_Technology_Stack.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Technology Stack</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/9_MVP.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MVP</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Levels</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth3 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/Levels/Cosmic_Structures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Cosmic Structures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/Levels/Particle_Accelerator.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Particle Accelerator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/Levels/Quantum_Realm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantum Realm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/Levels/Relativistic_Space_Time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Relativistic Space-Time</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/Subatomic_Playground/Claude/Levels/Wormhole_Nexus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wormhole Nexus</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../content/projects/blog_tech_stack/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blog Tech Stack</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/blog_tech_stack/memberships/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Membership Paywalls</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">
 <span class="menu-text">Quarto</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/blog_tech_stack/quarto/quarto-links.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quarto Links</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../content/projects/blog_tech_stack/quarto/quarto-vercel-build.sh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vercel Quarto build.sh</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#basic-functions" id="toc-basic-functions" class="nav-link active" data-scroll-target="#basic-functions">Basic Functions</a>
  <ul>
  <li><a href="#from_pretrained" id="toc-from_pretrained" class="nav-link" data-scroll-target="#from_pretrained">1. from_pretrained()</a></li>
  <li><a href="#encode-and-encode_plus" id="toc-encode-and-encode_plus" class="nav-link" data-scroll-target="#encode-and-encode_plus">2. encode() and encode_plus()</a></li>
  <li><a href="#decode" id="toc-decode" class="nav-link" data-scroll-target="#decode">3. decode()</a></li>
  <li><a href="#batch_encode_plus-and-call" id="toc-batch_encode_plus-and-call" class="nav-link" data-scroll-target="#batch_encode_plus-and-call">4. batch_encode_plus() and <strong>call</strong>()</a></li>
  <li><a href="#convert_tokens_to_ids-and-convert_ids_to_tokens" id="toc-convert_tokens_to_ids-and-convert_ids_to_tokens" class="nav-link" data-scroll-target="#convert_tokens_to_ids-and-convert_ids_to_tokens">5. convert_tokens_to_ids() and convert_ids_to_tokens()</a></li>
  <li><a href="#usage-tips" id="toc-usage-tips" class="nav-link" data-scroll-target="#usage-tips">Usage Tips:</a></li>
  </ul></li>
  <li><a href="#worked-example" id="toc-worked-example" class="nav-link" data-scroll-target="#worked-example">Worked Example</a>
  <ul>
  <li><a href="#setting-up" id="toc-setting-up" class="nav-link" data-scroll-target="#setting-up">Setting Up</a></li>
  </ul></li>
  <li><a href="#step-1-initializing-the-tokenizer" id="toc-step-1-initializing-the-tokenizer" class="nav-link" data-scroll-target="#step-1-initializing-the-tokenizer">Step 1: Initializing the Tokenizer</a>
  <ul>
  <li><a href="#step-2-tokenizing-text" id="toc-step-2-tokenizing-text" class="nav-link" data-scroll-target="#step-2-tokenizing-text">Step 2: Tokenizing Text</a></li>
  <li><a href="#step-3-encoding" id="toc-step-3-encoding" class="nav-link" data-scroll-target="#step-3-encoding">Step 3: Encoding</a></li>
  <li><a href="#step-4-decoding" id="toc-step-4-decoding" class="nav-link" data-scroll-target="#step-4-decoding">Step 4: Decoding</a></li>
  <li><a href="#complete-python-script" id="toc-complete-python-script" class="nav-link" data-scroll-target="#complete-python-script">Complete Python Script</a></li>
  </ul></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a>
  <ul>
  <li><a href="#bert-tokenizers" id="toc-bert-tokenizers" class="nav-link" data-scroll-target="#bert-tokenizers">1. BERT Tokenizers</a></li>
  <li><a href="#gpt-and-gpt-2-tokenizers" id="toc-gpt-and-gpt-2-tokenizers" class="nav-link" data-scroll-target="#gpt-and-gpt-2-tokenizers">2. GPT and GPT-2 Tokenizers</a></li>
  <li><a href="#roberta-tokenizers" id="toc-roberta-tokenizers" class="nav-link" data-scroll-target="#roberta-tokenizers">3. RoBERTa Tokenizers</a></li>
  <li><a href="#distilbert-tokenizers" id="toc-distilbert-tokenizers" class="nav-link" data-scroll-target="#distilbert-tokenizers">4. DistilBERT Tokenizers</a></li>
  <li><a href="#xlnet-tokenizers" id="toc-xlnet-tokenizers" class="nav-link" data-scroll-target="#xlnet-tokenizers">5. XLNet Tokenizers</a></li>
  <li><a href="#t5-tokenizers" id="toc-t5-tokenizers" class="nav-link" data-scroll-target="#t5-tokenizers">6. T5 Tokenizers</a></li>
  <li><a href="#albert-tokenizers" id="toc-albert-tokenizers" class="nav-link" data-scroll-target="#albert-tokenizers">7. ALBERT Tokenizers</a></li>
  <li><a href="#bart-tokenizers" id="toc-bart-tokenizers" class="nav-link" data-scroll-target="#bart-tokenizers">8. BART Tokenizers</a></li>
  <li><a href="#electra-tokenizers" id="toc-electra-tokenizers" class="nav-link" data-scroll-target="#electra-tokenizers">9. ELECTRA Tokenizers</a></li>
  <li><a href="#deberta-tokenizers" id="toc-deberta-tokenizers" class="nav-link" data-scroll-target="#deberta-tokenizers">10. DeBERTa Tokenizers</a></li>
  <li><a href="#specialized-tokenizers" id="toc-specialized-tokenizers" class="nav-link" data-scroll-target="#specialized-tokenizers">Specialized Tokenizers</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/JamesMcGuigan/blog/edit/master/content/projects/generative_ai/huggingface/transformers/AutoTokenizer.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">AutoTokenizer</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>GPT4 </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="basic-functions" class="level2">
<h2 class="anchored" data-anchor-id="basic-functions">Basic Functions</h2>
<p>The <code>AutoTokenizer</code> class in the Hugging Face <code>transformers</code> library is a versatile tool designed to handle tokenization tasks for a wide range of pre-trained models. It abstracts away the specifics of each tokenizer, allowing you to work with various models without worrying about the underlying tokenizer details. Here’s a rundown of some basic functions and how they’re typically used:</p>
<section id="from_pretrained" class="level3">
<h3 class="anchored" data-anchor-id="from_pretrained">1. from_pretrained()</h3>
<p>The most common way to instantiate a tokenizer. This method automatically fetches and loads the tokenizer associated with a given pre-trained model.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="encode-and-encode_plus" class="level3">
<h3 class="anchored" data-anchor-id="encode-and-encode_plus">2. encode() and encode_plus()</h3>
<p>These methods convert text into token IDs. <code>encode()</code> returns a list of token IDs, while <code>encode_plus()</code> provides additional outputs like attention masks, token type IDs, and more, typically required by models for proper input formatting.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple encoding</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>token_ids <span class="op">=</span> tokenizer.encode(<span class="st">"Hello, world!"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Advanced encoding with additional features</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> tokenizer.encode_plus(</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Hello, world!"</span>,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    add_special_tokens<span class="op">=</span><span class="va">True</span>,  <span class="co"># Adds special tokens (like [CLS], [SEP])</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    return_attention_mask<span class="op">=</span><span class="va">True</span>,  <span class="co"># Returns attention mask</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    pad_to_max_length<span class="op">=</span><span class="va">True</span>,  <span class="co"># Pads to max sequence length</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    max_length<span class="op">=</span><span class="dv">512</span>,  <span class="co"># Specifies max sequence length</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    return_tensors<span class="op">=</span><span class="st">'pt'</span>,  <span class="co"># Returns PyTorch tensors</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="decode" class="level3">
<h3 class="anchored" data-anchor-id="decode">3. decode()</h3>
<p>This function converts token IDs back to readable text. It’s particularly useful for interpreting the outputs of your model.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>decoded_text <span class="op">=</span> tokenizer.decode(token_ids)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="batch_encode_plus-and-call" class="level3">
<h3 class="anchored" data-anchor-id="batch_encode_plus-and-call">4. batch_encode_plus() and <strong>call</strong>()</h3>
<p>For processing multiple texts at once (like sentences or documents), these methods are very efficient. They return a batch of encoded inputs with consistent length, which is essential for feeding batches of data into your model.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>batch_encoded <span class="op">=</span> tokenizer.batch_encode_plus(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"Hello, world!"</span>, <span class="st">"Another text."</span>],</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    padding<span class="op">=</span><span class="va">True</span>,  <span class="co"># Adds padding to ensure consistent length</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    return_tensors<span class="op">=</span><span class="st">'pt'</span>  <span class="co"># Returns PyTorch tensors</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Or using __call__(), which is equivalent to using batch_encode_plus()</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>batch_encoded <span class="op">=</span> tokenizer(</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"Hello, world!"</span>, <span class="st">"Another text."</span>],</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    padding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    return_tensors<span class="op">=</span><span class="st">'pt'</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="convert_tokens_to_ids-and-convert_ids_to_tokens" class="level3">
<h3 class="anchored" data-anchor-id="convert_tokens_to_ids-and-convert_ids_to_tokens">5. convert_tokens_to_ids() and convert_ids_to_tokens()</h3>
<p>These methods are for converting between tokens and their corresponding IDs, allowing for more granular manipulation of the tokenization process.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> [<span class="st">'[CLS]'</span>, <span class="st">'hello'</span>, <span class="st">','</span>, <span class="st">'world'</span>, <span class="st">'!'</span>, <span class="st">'[SEP]'</span>]</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>token_ids <span class="op">=</span> tokenizer.convert_tokens_to_ids(tokens)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert back to tokens</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>tokens_back <span class="op">=</span> tokenizer.convert_ids_to_tokens(token_ids)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="usage-tips" class="level3">
<h3 class="anchored" data-anchor-id="usage-tips">Usage Tips:</h3>
<ul>
<li>When using these functions, especially for training or evaluation, make sure to understand the expected input format of your model. For instance, some models require special tokens to be added to the inputs, which <code>encode_plus()</code> and <code>__call__()</code> can handle with the <code>add_special_tokens=True</code> argument.</li>
<li>The <code>padding</code> and <code>truncation</code> arguments are crucial for batch processing to ensure all inputs are of the same length. This is important for models that expect fixed-size inputs.</li>
<li>The <code>return_tensors</code> argument allows you to specify the format of the returned tensors (<code>'pt'</code> for PyTorch, <code>'tf'</code> for TensorFlow, and <code>'np'</code> for NumPy arrays), ensuring compatibility with your training or inference pipeline.</li>
</ul>
<p>These basic functions of <code>AutoTokenizer</code> provide a strong foundation for preprocessing text data, making it easier to work with various NLP models. If you have any specific use cases or advanced scenarios in mind, feel free to dive deeper or ask for more detailed examples!</p>
</section>
</section>
<section id="worked-example" class="level2">
<h2 class="anchored" data-anchor-id="worked-example">Worked Example</h2>
<p>Let’s work through a detailed example using <code>AutoTokenizer</code> from the Hugging Face <code>transformers</code> library. We’ll use the <code>bert-base-uncased</code> model as our base for this example, focusing on tokenization, encoding, and decoding processes.</p>
<section id="setting-up" class="level3">
<h3 class="anchored" data-anchor-id="setting-up">Setting Up</h3>
<p>First, ensure you have the <code>transformers</code> library installed. If not, you can install it using pip:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install transformers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="step-1-initializing-the-tokenizer" class="level2">
<h2 class="anchored" data-anchor-id="step-1-initializing-the-tokenizer">Step 1: Initializing the Tokenizer</h2>
<p>We’ll start by importing <code>AutoTokenizer</code> and initializing it with the <code>bert-base-uncased</code> pre-trained model.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="step-2-tokenizing-text" class="level3">
<h3 class="anchored" data-anchor-id="step-2-tokenizing-text">Step 2: Tokenizing Text</h3>
<p>Let’s tokenize a simple sentence: “Hello, world! This is a test.”</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Hello, world! This is a test."</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize the text</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> tokenizer.tokenize(text)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Output:</strong></p>
<pre><code>['hello', ',', 'world', '!', 'this', 'is', 'a', 'test', '.']</code></pre>
<p>Here, the text is lowercased (since we’re using the <code>uncased</code> version of BERT), and punctuation is separated as individual tokens.</p>
</section>
<section id="step-3-encoding" class="level3">
<h3 class="anchored" data-anchor-id="step-3-encoding">Step 3: Encoding</h3>
<p>Now, we’ll convert our text into token IDs using <code>encode_plus</code>, which provides additional outputs necessary for model inputs.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>encoded_inputs <span class="op">=</span> tokenizer.encode_plus(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    text,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    add_special_tokens<span class="op">=</span><span class="va">True</span>,  <span class="co"># Adds [CLS] and [SEP]</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    return_attention_mask<span class="op">=</span><span class="va">True</span>,  <span class="co"># Generates attention mask</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    padding<span class="op">=</span><span class="st">'max_length'</span>,  <span class="co"># Pads to a length</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    max_length<span class="op">=</span><span class="dv">20</span>,  <span class="co"># Specifies maximum length</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    return_tensors<span class="op">=</span><span class="st">'pt'</span>,  <span class="co"># Returns PyTorch tensors</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(encoded_inputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Output:</strong></p>
<p>This will produce a dictionary containing the following keys: <code>input_ids</code>, <code>token_type_ids</code>, and <code>attention_mask</code>, all of which are PyTorch tensors due to <code>return_tensors='pt'</code>. The <code>input_ids</code> are the token IDs, <code>token_type_ids</code> are used for models that require a distinction between sentence pairs (not necessary here), and <code>attention_mask</code> indicates to the model which tokens should be attended to, and which should not (e.g., padding tokens).</p>
</section>
<section id="step-4-decoding" class="level3">
<h3 class="anchored" data-anchor-id="step-4-decoding">Step 4: Decoding</h3>
<p>Finally, let’s decode the token IDs back to text to see how the tokenizer converts IDs back into a string. We’ll decode the <code>input_ids</code> from our encoded inputs.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>decoded_text <span class="op">=</span> tokenizer.decode(encoded_inputs[<span class="st">'input_ids'</span>][<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(decoded_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Output:</strong></p>
<pre><code>hello, world! this is a test.</code></pre>
<p>The decoded text is a clean version of the original text, omitting special tokens that were added during the encoding process.</p>
</section>
<section id="complete-python-script" class="level3">
<h3 class="anchored" data-anchor-id="complete-python-script">Complete Python Script</h3>
<p>Here’s the entire process in one Python script:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the tokenizer</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># The text to tokenize, encode, and decode</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Hello, world! This is a test."</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize the text</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> tokenizer.tokenize(text)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tokens:"</span>, tokens)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode the text</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>encoded_inputs <span class="op">=</span> tokenizer.encode_plus(</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    text,</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    add_special_tokens<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    return_attention_mask<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    padding<span class="op">=</span><span class="st">'max_length'</span>,</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    max_length<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    return_tensors<span class="op">=</span><span class="st">'pt'</span>,</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Encoded Inputs:"</span>, encoded_inputs)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Decode the token IDs back to text</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>decoded_text <span class="op">=</span> tokenizer.decode(encoded_inputs[<span class="st">'input_ids'</span>][<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Decoded Text:"</span>, decoded_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This script demonstrates the basic functionality of the <code>AutoTokenizer</code>: tokenizing a piece of text, encoding it into a format suitable for a model, and then decoding the output back into human-readable text. This process is fundamental for preparing text data for training or inference with NLP models.</p>
</section>
</section>
<section id="models" class="level2">
<h2 class="anchored" data-anchor-id="models">Models</h2>
<p>The Hugging Face <code>transformers</code> library supports a wide range of tokenizer models, each designed to work with specific types of pre-trained language models. These tokenizers can handle different tokenization strategies, such as Byte-Pair Encoding (BPE), SentencePiece, WordPiece, and more. Below is a list of some of the tokenizer model families and the pre-trained models they are associated with:</p>
<section id="bert-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="bert-tokenizers">1. BERT Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> BERT (Bidirectional Encoder Representations from Transformers)</li>
<li><strong>Example Models:</strong> <code>bert-base-uncased</code>, <code>bert-large-cased</code>, etc.</li>
<li><strong>Tokenizer:</strong> WordPiece</li>
</ul>
</section>
<section id="gpt-and-gpt-2-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="gpt-and-gpt-2-tokenizers">2. GPT and GPT-2 Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> GPT (Generative Pre-trained Transformer), GPT-2</li>
<li><strong>Example Models:</strong> <code>openai-gpt</code>, <code>gpt2</code>, <code>gpt2-medium</code>, <code>gpt2-large</code>, <code>gpt2-xl</code></li>
<li><strong>Tokenizer:</strong> Byte-Pair Encoding (BPE)</li>
</ul>
</section>
<section id="roberta-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="roberta-tokenizers">3. RoBERTa Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> RoBERTa (Robustly Optimized BERT Approach)</li>
<li><strong>Example Models:</strong> <code>roberta-base</code>, <code>roberta-large</code>, <code>roberta-large-mnli</code></li>
<li><strong>Tokenizer:</strong> Byte-Level BPE</li>
</ul>
</section>
<section id="distilbert-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="distilbert-tokenizers">4. DistilBERT Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> DistilBERT (a distilled version of BERT)</li>
<li><strong>Example Models:</strong> <code>distilbert-base-uncased</code>, <code>distilbert-base-cased</code></li>
<li><strong>Tokenizer:</strong> WordPiece</li>
</ul>
</section>
<section id="xlnet-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="xlnet-tokenizers">5. XLNet Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> XLNet</li>
<li><strong>Example Models:</strong> <code>xlnet-base-cased</code>, <code>xlnet-large-cased</code></li>
<li><strong>Tokenizer:</strong> SentencePiece</li>
</ul>
</section>
<section id="t5-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="t5-tokenizers">6. T5 Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> T5 (Text-to-Text Transfer Transformer)</li>
<li><strong>Example Models:</strong> <code>t5-small</code>, <code>t5-base</code>, <code>t5-large</code>, <code>t5-3b</code>, <code>t5-11b</code></li>
<li><strong>Tokenizer:</strong> SentencePiece</li>
</ul>
</section>
<section id="albert-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="albert-tokenizers">7. ALBERT Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> ALBERT (A Lite BERT)</li>
<li><strong>Example Models:</strong> <code>albert-base-v2</code>, <code>albert-large-v2</code>, etc.</li>
<li><strong>Tokenizer:</strong> SentencePiece</li>
</ul>
</section>
<section id="bart-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="bart-tokenizers">8. BART Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> BART (Bidirectional and Auto-Regressive Transformers)</li>
<li><strong>Example Models:</strong> <code>facebook/bart-base</code>, <code>facebook/bart-large</code></li>
<li><strong>Tokenizer:</strong> Byte-Level BPE</li>
</ul>
</section>
<section id="electra-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="electra-tokenizers">9. ELECTRA Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> ELECTRA</li>
<li><strong>Example Models:</strong> <code>google/electra-small-generator</code>, <code>google/electra-base-discriminator</code></li>
<li><strong>Tokenizer:</strong> WordPiece</li>
</ul>
</section>
<section id="deberta-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="deberta-tokenizers">10. DeBERTa Tokenizers</h3>
<ul>
<li><strong>Model Family:</strong> DeBERTa (Decoding-enhanced BERT with Disentangled Attention)</li>
<li><strong>Example Models:</strong> <code>microsoft/deberta-base</code>, <code>microsoft/deberta-large</code></li>
<li><strong>Tokenizer:</strong> SentencePiece</li>
</ul>
</section>
<section id="specialized-tokenizers" class="level3">
<h3 class="anchored" data-anchor-id="specialized-tokenizers">Specialized Tokenizers</h3>
<ul>
<li><strong>CTRL (Salesforce):</strong> Uses a special tokenizer with additional control codes.</li>
<li><strong>Longformer:</strong> Designed for longer documents by providing an extended positional encoding.</li>
<li><strong>Reformer:</strong> Optimized for efficiency with reversible layers and locality-sensitive hashing.</li>
</ul>
<p>Each tokenizer is tailored to its respective model architecture, ensuring that text inputs are correctly preprocessed for training or inference tasks. When using <code>AutoTokenizer</code> with the <code>from_pretrained</code> method, the correct tokenizer for your chosen pre-trained model is automatically instantiated, abstracting away the need to manually select the appropriate tokenizer class.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>